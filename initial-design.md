Below is an endâ€‘toâ€‘end design that gives **(a)** a clearly defined *fileâ€‘system & markdown structure* and **(b)** a precise, repeatable *algorithm* an AI (or human) reviewer can follow for every source file.  Copy this verbatim into your repository as `REVIEW_GUIDE.md` and point each reviewer to it.

---

## 1. Repository layout for reviews

```
/code/                       âŸµ original source (readâ€‘only for reviewers)
/reviews/                    âŸµ everything produced by reviews
â”‚
â”œâ”€â”€ _MASTER.md               âŸµ single sourceâ€‘ofâ€‘truth progress ledger
â”œâ”€â”€ _TAGS.yml                âŸµ shared vocab: severities, categories â€¦ (optional)
â”œâ”€â”€ _DEPENDENCIES.yml        âŸµ graph of fileâ€‘toâ€‘file relationships
â”‚
â”œâ”€â”€ modules/                 âŸµ mirrors /code/ directory tree 1â€‘forâ€‘1
â”‚   â””â”€â”€ <moduleâ€‘name>/       
â”‚       â”œâ”€â”€ README.md        âŸµ moduleâ€‘level synthesis (created last)
â”‚       â””â”€â”€ <file>.md        âŸµ one review file per real code file
â”‚
â””â”€â”€ system/
    â”œâ”€â”€ HOTSPOTS.md          âŸµ auto/handâ€‘curated list of crossâ€‘cutting issues
    â””â”€â”€ METRICS_SUMMARY.md   âŸµ repoâ€‘wide score rollâ€‘ups
```

### 1.1  `_MASTER.md`  (progress ledger)

A markdown table (one row per code file) tracked under versionâ€‘control.

| FileÂ Path         | Lang | LOC | ReviewedÂ ? | ReviewÂ Date | Reviewer | Security | Perf | Maint | Consistency | BestÂ Pract. | CodeÂ Smell | OpenÂ Issues | Dep. Count |
| ----------------- | ---- | --- | ---------- | ----------- | -------- | -------- | ---- | ----- | ----------- | ----------- | ---------- | ----------- | ---------- |
| `src/api/user.js` | JS   | 428 | âœ…          | 2025â€‘07â€‘05  | `AIâ€‘A`   | 3        | 4    | 4     | 5           | 4           | 3          | 5           | 7          |

*Scores are 1â€‘5 (5 = excellent). â€œOpenÂ Issuesâ€ is a count of unresolved items in that file.*

### 1.2  Review file template  (`/reviews/modules/<module>/<file>.md`)

```markdown
---
file: src/api/user.js
language: JavaScript
loc: 428
reviewer: AIâ€‘A
date: 2025â€‘07â€‘05
status: complete           # draft | complete | needsâ€‘followâ€‘up
metrics:
  security:        {score: 3, open_issues: 2}
  performance:     {score: 4, open_issues: 1}
  maintainability: {score: 4, open_issues: 0}
  consistency:     {score: 5, open_issues: 0}
  best_practices:  {score: 4, open_issues: 1}
  code_smell:      {score: 3, open_issues: 1}
dependencies:
  - src/common/crypto.js         # imported by this file
  - src/models/userModel.js
reverse_dependencies: []         # to be autoâ€‘populated later
---

# 1. Summary  
*Brief, highâ€‘level statement of what the file does and overall health.*

# 2. Detailed findings  

| # | Category | Severity | Location | Description | Recommendation |
|---|----------|----------|----------|-------------|----------------|
| 1 | Security | **High** | L67â€‘82   | Unsanitised input in JWT decode | Validate & escape input or use vetted library â€¦ |
| 2 | Perf | **Med** | L120 | N+1 DB queries inside loop | Batch queries â€¦ |

# 3. Positive observations  
*E.g., good test coverage, clear naming â€¦*

# 4. Context & links  
- Related ADRs: ADRâ€‘12â€‘Authâ€‘Strategy  
- Unit tests: `tests/api/user.test.js`  
- Design docs: `/docs/auth.md`

# 5. Checklist (pass / fail)  
- [x] Lints clean  
- [ ] Threat model updated  
- [x] Logging at appropriate levels  

```

### 1.3  `_DEPENDENCIES.yml`

```yaml
src/api/user.js:
  outbound:
    - src/common/crypto.js
    - src/models/userModel.js
  inbound:        # filled by script after all files reviewed
    - src/server.js
```

### 1.4  `system/HOTSPOTS.md`

*Automatically or manually gather issues that involve **multiple files** (e.g., shared secret management, crossâ€‘module circular deps).  Link to individual findings by `file#line`.*

---

## 2. Endâ€‘toâ€‘end workflow

### PhaseÂ 0 â€“ Setup (oneâ€‘time)

1. **Clone** the code repository into `/code`.
2. **Inventory** every code file (include language & LOC).
3. Generate skeletons:

   * `_MASTER.md` preâ€‘populated with one row per file (ReviewedÂ ?â€¯=â€¯âŒ).
   * Empty review markdown stub for each file under `/reviews/modules/...`.
   * Initial empty `_DEPENDENCIES.yml`.

*(A helper script can automate 2â€‘3.)*

### PhaseÂ 1 â€“ Perâ€‘file review loop

> **Input**: Path to *one* unreviewed file (`FILE`).
> **Output**: Updated review markdown, `_MASTER.md`, `_DEPENDENCIES.yml`.

| Step | Action                                                                                                                       | Notes                                                                                                  |
| ---- | ---------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------ |
| 1    | *Lock file* in `_MASTER.md` (mark â€œğŸ”’Â inâ€‘progressâ€).                                                                         | Prevent duplicate work.                                                                                |
| 2    | **Load context**: code of `FILE`, its tests, design docs, lint results.                                                      |                                                                                                        |
| 3    | **Static analysis** (security linters, complexity, style) & quick runtime probe if feasible.                                 | Retain artefacts in a `/reports/<file>/` folder if big.                                                |
| 4    | **Assess six categories** in order:<br>Security â†’ Performance â†’ Maintainability â†’ Consistency â†’ BestÂ Practices â†’ CodeÂ Smell. | For each:<br>â€¢ list specific findings with severity (High/Med/Low) and line refs;<br>â€¢ give 1â€‘5 score. |
| 5    | **Identify dependencies**:<br>â€¢ Imports / includes / external calls.<br>â€¢ Capture in `dependencies:` list.                   | Regex parse or languageâ€‘aware parser.                                                                  |
| 6    | **Populate review markdown** (use template Â§1.2).                                                                            | Replace placeholders, keep sections even if empty.                                                     |
| 7    | **Update `_MASTER.md`**:<br>â€¢ ReviewedÂ ? = âœ….<br>â€¢ Fill scores & issue counts.<br>â€¢ Clear lock.                              | Keep row order constant for diff readability.                                                          |
| 8    | **Append to `_DEPENDENCIES.yml`** outbound links discovered.                                                                 | Merging if key already exists.                                                                         |
| 9    | **Commit** all changes (`git commit -m "Reviewed FILE"`).                                                                    | CI can run linkâ€‘checker on commit.                                                                     |

> *At this moment the file is **done** and can contribute to systemâ€‘level views.*

### PhaseÂ 2 â€“ Systemâ€‘level aggregation (runs periodically)

| Step | Action                                                                                                                      | Produced artefact         |
| ---- | --------------------------------------------------------------------------------------------------------------------------- | ------------------------- |
| A    | Compute reverse dependencies using `_DEPENDENCIES.yml`; write them back in each fileâ€™s `reverse_dependencies` list.         | Updated review md files.  |
| B    | Reâ€‘compute repo KPI scores (averages, stdâ€‘dev); write `system/METRICS_SUMMARY.md`.                                          | Overall health dashboard. |
| C    | Detect patterns: same issue ID in â‰¥â€¯2 files, circular dependencies, duplicated secrets, etc.  List in `system/HOTSPOTS.md`. | Crossâ€‘cutting insights.   |

*(These can be scripted to run in CI on every review commit.)*

---

## 3. Precise algorithm for the reviewer AI (copy/paste into prompt)

> **ROLE**: *You are the File Reviewer AI.*
> **OBJECTIVE**: Analyse **exactly one** source file and populate its review markdown while updating the master ledger.
> **INPUTS**:
>
> * `FILE_PATH` â€“ absolute path inside `/code/â€¦`
> * `REPO_ROOT/reviews` â€“ writable review workspace
> * `METRICS` â€“ fixed list: `Security, Performance, Maintainability, Consistency, Best_Practices, Code_Smell`
>   **OUTPUTS** (all in markdown):
> * `/reviews/modules/.../<FILE_NAME>.md` â€“ filled template
> * Updated row in `/reviews/_MASTER.md`
> * Added outbound deps in `/reviews/_DEPENDENCIES.yml`

### Algorithm

```
1. Open /reviews/_MASTER.md; mark FILE_PATH row â€œğŸ”’ inâ€‘progressâ€.
2. Read source code; detect language & LOC.
3. Run static tools:
     â€¢ Linter / formatter
     â€¢ Security scanner (e.g., Bandit, ESLintâ€‘security)
     â€¢ Complexity metrics
4. For each METRIC in order:
     a. Scan code manually + tool results.
     b. Record findings (line numbers, description, recommendation, severity).
     c. Assign 1â€‘5 score & count open issues.
5. Parse imports / includes; list unique outbound dependencies.
6. Fill review markdown template sections (#1â€“#5).
7. Reâ€‘open /reviews/_MASTER.md; overwrite row:
     Reviewed? âœ…, Review_Date=TODAY, Reviewer=AIâ€‘ID,
     fill metric scores & issue counts, Dep.Count = len(outbound deps).
8. Update /reviews/_DEPENDENCIES.yml:
     Append/merge:
       FILE_PATH:
         outbound: [depsâ€¦]
9. Save all files. Remove â€œğŸ”’â€.
10. End with message: â€œReview of FILE_PATH complete.â€  (No extra commentary.)
```

---

## 4. Scoring rubric (1â€“5)

| Score | Description                                      |
| ----- | ------------------------------------------------ |
| 5     | Exemplary â€“ no actionable findings.              |
| 4     | Minor nits only; no medium/high severity issues. |
| 3     | At least one medium severity or several lows.    |
| 2     | High severity issue(s) but fixable locally.      |
| 1     | Critical flaws; rewrite advised.                 |

*(Same rubric applied for every metric.)*

---

## 5. Naming & crossâ€‘reference conventions

* **Issue IDs**: `FILE:ISSUE#:CATEGORY` (e.g., `src/api/user.js:1:Security`) â€“ unique in repo.
* **Module README** files created **after** all contained files are reviewed, summarising patterns & open items.
* **Linking**: Use relative paths so browsing on GitHub renders correctly.

---

### Why this works

* **Deterministic**: Every action & file path is spelled out.
* **Composable**: Perâ€‘file reviews are standâ€‘alone yet machineâ€‘mergeable for system views.
* **Lowâ€‘friction tooling**: Pure Markdown/YAML; no DB required.
* **CIâ€‘friendly**: Scripts can validate schema, render dashboards, and fail builds on highâ€‘severity issues.

Hand this guide to any reviewing engine (AI or human) and it will know **exactly** where to write, what to fill, and how to keep the overall review corpus coherent and inspectable.
